#!/usr/bin/env python3
"""
Test rapide d'entra√Ænement pour v√©rifier que les NaN ont disparu
‚úÖ FINAL - Compatible avec les noms originaux et imports corrig√©s
"""

import torch
import pickle
import sys
import os
from torch_geometric.loader import DataLoader
from sklearn.preprocessing import LabelEncoder

sys.path.append("src")
from config import get_cfg_defaults
from model.xaiguiformer_pipeline import XaiGuiFormer

def test_forward_pass():
    """Test du forward pass sur un petit batch"""
    
    print("=== TEST FORWARD PASS FINAL ===")
    
    # Charger config
    cfg = get_cfg_defaults()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")
    
    # Charger donn√©es
    dataset_path = "data/TDBRAIN/tokens/xai_graphs.pkl"
    with open(dataset_path, "rb") as f:
        graphs = pickle.load(f)
    
    print(f"Graphes charg√©s: {len(graphs)}")
    
    # Pr√©parer labels
    all_labels = [g.y.item() for g in graphs]
    label_encoder = LabelEncoder()
    label_encoder.fit(all_labels)
    num_classes = len(label_encoder.classes_)
    
    # Mettre √† jour config
    cfg.defrost()
    cfg.model.num_classes = num_classes
    cfg.freeze()
    
    print(f"Classes: {num_classes} - {label_encoder.classes_}")
    
    # Cr√©er loader (petit batch)
    loader = DataLoader(graphs[:4], batch_size=2, shuffle=False)
    
    # Cr√©er mod√®le
    model = XaiGuiFormer(config=cfg, training_graphs=graphs).to(device)
    print(f"Mod√®le cr√©√© - param√®tres: {sum(p.numel() for p in model.parameters()):,}")
    
    # Test forward
    model.train()
    for i, batch in enumerate(loader):
        print(f"\n--- Batch {i} ---")
        batch = batch.to(device)
        
        # Debug dimensions
        print(f"x_tokens shape: {batch.x_tokens.shape}")
        print(f"freq_bounds shape: {batch.freq_bounds.shape}")
        print(f"age shape: {batch.age.shape}")
        print(f"gender shape: {batch.gender.shape}")
        print(f"y shape: {batch.y.shape}")
        
        # ‚úÖ CORRECTION : Restructurer le batching PyG
        B = batch.y.shape[0]  # Nombre d'√©chantillons dans le batch
        
        # PyG concat√®ne les tenseurs ‚Üí il faut les reshaper
        if batch.x_tokens.dim() == 2:  # [B*Freq, d] au lieu de [B, Freq, d]
            Freq = batch.x_tokens.shape[0] // B  # 36 // 2 = 18
            d = batch.x_tokens.shape[1]  # 528
            
            # Reshape en format attendu
            batch.x_tokens = batch.x_tokens.view(B, Freq, d)
            batch.freq_bounds = batch.freq_bounds.view(B, Freq, 2)
            
            print(f"‚úÖ Reshaped - x_tokens: {batch.x_tokens.shape}, freq_bounds: {batch.freq_bounds.shape}")
        
        # Prendre freq_bounds du premier √©chantillon (ils sont identiques)
        freq_bounds = batch.freq_bounds[0]  # [Freq, 2]
        age = batch.age.view(-1, 1)         # [B, 1] 
        gender = batch.gender.view(-1, 1)   # [B, 1]
        
        print(f"Input shapes:")
        print(f"  freq_bounds: {freq_bounds.shape}")
        print(f"  age: {age.shape} - values: {age.flatten()}")
        print(f"  gender: {gender.shape} - values: {gender.flatten()}")
        
        # ‚úÖ V√âRIFICATION : pas de NaN dans les inputs
        if torch.isnan(age).any():
            print("‚ùå NaN d√©tect√© dans age!")
            return False
        if torch.isnan(gender).any():
            print("‚ùå NaN d√©tect√© dans gender!")
            return False
        if torch.isnan(batch.x_tokens).any():
            print("‚ùå NaN d√©tect√© dans x_tokens!")
            return False
            
        print("‚úÖ Aucun NaN d√©tect√© dans les inputs")
        
        try:
            # Forward pass
            loss = model(batch, freq_bounds, age, gender, batch.y)
            
            print(f"‚úÖ Forward r√©ussi!")
            print(f"Loss: {loss.item():.6f}")
            print(f"Loss is NaN: {torch.isnan(loss)}")
            
            if torch.isnan(loss):
                print("‚ùå Loss = NaN - probl√®me dans le forward!")
                return False
            
            # Test backward
            loss.backward()
            print("‚úÖ Backward r√©ussi!")
            
        except Exception as e:
            print(f"‚ùå Erreur dans forward/backward: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    print("\nüéâ TOUS LES TESTS PASS√âS - EXPLAINER CAPTUM FONCTIONNEL!")
    return True

if __name__ == "__main__":
    success = test_forward_pass()
    if success:
        print("\n‚úÖ Pr√™t pour l'entra√Ænement complet!")
        print("‚úÖ Plus de warnings 'Layer explainer failed'!")
        print("‚úÖ Explanations multi-couches fonctionnelles!")
    else:
        print("\n‚ùå Il reste des probl√®mes √† corriger")