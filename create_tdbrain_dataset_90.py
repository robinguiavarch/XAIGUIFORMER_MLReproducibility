#!/usr/bin/env python3
"""
Script pour crÃ©er un dataset de 90 patients TDBRAIN avec rÃ©partition Ã©quilibrÃ©e
- MDD: 22 patients
- ADHD: 22 patients  
- SMC: 22 patients
- HEALTHY: 22 patients
- Splits stratifiÃ©s: Train(50) / Val(20) / Test(20)
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import os

def create_tdbrain_90_dataset():
    """CrÃ©e un dataset de 90 patients avec rÃ©partition Ã©quilibrÃ©e"""
    
    # Configuration
    input_file = "data/TDBRAIN_participants_V2.csv"
    output_file = "data/TDBRAIN_90_patients.csv"
    
    # RÃ©partition cible (88 patients = 22Ã—4)
    target_distribution = {
        'MDD': 22,
        'ADHD': 22, 
        'SMC': 22,
        'HEALTHY': 22
    }
    total_patients = sum(target_distribution.values())  # 88 patients
    
    print("=== CrÃ©ation du dataset TDBRAIN 88 patients ===")
    print(f"ğŸ“– Lecture du fichier: {input_file}")
    
    try:
        df = pd.read_csv(input_file)
        print(f"âœ… Fichier chargÃ©: {len(df)} lignes")
        
    except FileNotFoundError:
        print(f"âŒ Fichier non trouvÃ©: {input_file}")
        return None
    except Exception as e:
        print(f"âŒ Erreur lors du chargement: {e}")
        return None
    
    # Nettoyer les donnÃ©es
    print(f"\nğŸ§¹ Nettoyage des donnÃ©es...")
    
    # Supprimer les NaN et valeurs indÃ©sirables
    df_clean = df.dropna(subset=['indication']).copy()
    excluded_values = ['REPLICATION', 'UNKNOWN']
    df_clean = df_clean[~df_clean['indication'].isin(excluded_values)].copy()
    
    print(f"  - Dataset nettoyÃ©: {len(df_clean)} patients")
    
    # VÃ©rifier la disponibilitÃ© des diagnostics
    diagnosis_counts = df_clean['indication'].value_counts()
    print(f"\nğŸ“Š VÃ©rification de la disponibilitÃ©:")
    
    all_available = True
    for diagnosis, target_count in target_distribution.items():
        available = diagnosis_counts.get(diagnosis, 0)
        status = "âœ…" if available >= target_count else "âŒ"
        print(f"  {status} {diagnosis}: {target_count} demandÃ©s, {available} disponibles")
        
        if available < target_count:
            all_available = False
    
    if not all_available:
        print(f"\nâŒ Pas assez de patients pour certains diagnostics!")
        return None
    
    # SÃ©lectionner les patients pour chaque diagnostic
    print(f"\nğŸ¯ SÃ©lection des patients...")
    selected_patients = []
    
    for diagnosis, target_count in target_distribution.items():
        # Filtrer les patients avec ce diagnostic
        diagnosis_patients = df_clean[df_clean['indication'] == diagnosis].copy()
        
        # SÃ©lection alÃ©atoire stratifiÃ©e par Ã¢ge et genre si possible
        if len(diagnosis_patients) > target_count:
            # Essayer une sÃ©lection stratifiÃ©e par genre
            try:
                if 'gender' in diagnosis_patients.columns:
                    # Stratifier par genre si possible
                    selected = []
                    for gender in [0, 1]:  # 0=Female, 1=Male
                        gender_patients = diagnosis_patients[diagnosis_patients['gender'] == gender]
                        if len(gender_patients) > 0:
                            n_to_select = min(len(gender_patients), target_count // 2)
                            selected.append(gender_patients.sample(n=n_to_select, random_state=42))
                    
                    selected_df = pd.concat(selected, ignore_index=True)
                    
                    # ComplÃ©ter si nÃ©cessaire
                    if len(selected_df) < target_count:
                        remaining_needed = target_count - len(selected_df)
                        remaining_patients = diagnosis_patients[~diagnosis_patients.index.isin(selected_df.index)]
                        additional = remaining_patients.sample(n=remaining_needed, random_state=42)
                        selected_df = pd.concat([selected_df, additional], ignore_index=True)
                    
                    # Prendre exactement le nombre voulu
                    selected_df = selected_df.sample(n=target_count, random_state=42)
                    
                else:
                    # SÃ©lection alÃ©atoire simple
                    selected_df = diagnosis_patients.sample(n=target_count, random_state=42)
                    
            except:
                # Fallback: sÃ©lection alÃ©atoire simple
                selected_df = diagnosis_patients.sample(n=target_count, random_state=42)
        else:
            # Prendre tous les patients disponibles
            selected_df = diagnosis_patients.copy()
        
        selected_patients.append(selected_df)
        print(f"  - {diagnosis}: {len(selected_df)} patients sÃ©lectionnÃ©s")
    
    # Combiner tous les patients sÃ©lectionnÃ©s
    final_dataset = pd.concat(selected_patients, ignore_index=True)
    
    print(f"\nğŸ“Š Dataset final:")
    print(f"  - Total: {len(final_dataset)} patients")
    
    # VÃ©rifier la rÃ©partition finale
    final_distribution = final_dataset['indication'].value_counts()
    for diagnosis, count in final_distribution.items():
        print(f"  - {diagnosis}: {count} patients")
    
    # CrÃ©er les splits stratifiÃ©s
    print(f"\nğŸ² CrÃ©ation des splits stratifiÃ©s...")
    
    # PrÃ©parer les labels pour la stratification
    X = final_dataset.drop('indication', axis=1)
    y = final_dataset['indication']
    
    try:
        # Premier split: Train (48) vs Temp (40)  
        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y, 
            train_size=48,
            test_size=40,
            stratify=y,
            random_state=42
        )
        
        # DeuxiÃ¨me split: Val (20) vs Test (20)
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp,
            train_size=20,
            test_size=20,
            stratify=y_temp,
            random_state=42
        )
        
        # Ajouter les colonnes de split
        final_dataset['split'] = 'unknown'
        final_dataset.loc[X_train.index, 'split'] = 'train'
        final_dataset.loc[X_val.index, 'split'] = 'val'
        final_dataset.loc[X_test.index, 'split'] = 'test'
        
        print(f"  âœ… Splits crÃ©Ã©s avec succÃ¨s:")
        split_counts = final_dataset['split'].value_counts()
        for split, count in split_counts.items():
            print(f"    - {split}: {count} patients")
        
        # VÃ©rifier la stratification par split
        print(f"\nğŸ“‹ RÃ©partition par diagnostic et split:")
        split_diagnosis = pd.crosstab(final_dataset['split'], final_dataset['indication'])
        print(split_diagnosis)
        
    except ValueError as e:
        print(f"âŒ Erreur lors de la stratification: {e}")
        print(f"ğŸ’¡ Fallback: split alÃ©atoire sans stratification")
        
        # Fallback: split alÃ©atoire
        final_dataset = final_dataset.sample(frac=1, random_state=42).reset_index(drop=True)
        total_patients = len(final_dataset)  # 88
        final_dataset['split'] = (['train'] * 48 + ['val'] * 20 + ['test'] * 20)[:total_patients]
    
    # Sauvegarder le dataset
    print(f"\nğŸ’¾ Sauvegarde du dataset...")
    
    # CrÃ©er le rÃ©pertoire si nÃ©cessaire
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    # Sauvegarder
    final_dataset.to_csv(output_file, index=False)
    print(f"âœ… Dataset sauvegardÃ©: {output_file}")
    
    # Statistiques dÃ©mographiques
    if 'age' in final_dataset.columns and 'gender' in final_dataset.columns:
        print(f"\nğŸ‘¥ Statistiques dÃ©mographiques:")
        print(f"  - Ã‚ge moyen: {final_dataset['age'].mean():.1f} Â± {final_dataset['age'].std():.1f} ans")
        print(f"  - Ã‚ge min-max: {final_dataset['age'].min():.0f} - {final_dataset['age'].max():.0f} ans")
        
        gender_counts = final_dataset['gender'].value_counts()
        for gender, count in gender_counts.items():
            gender_label = "Femme" if gender == 0 else "Homme"
            percentage = (count / len(final_dataset)) * 100
            print(f"  - {gender_label}: {count} patients ({percentage:.1f}%)")
    
    return final_dataset

def main():
    """Fonction principale"""
    print("ğŸš€ DÃ©marrage de la crÃ©ation du dataset TDBRAIN 88 patients")
    
    dataset = create_tdbrain_90_dataset()
    
    if dataset is not None:
        print(f"\nğŸ‰ Dataset crÃ©Ã© avec succÃ¨s!")
        print(f"PrÃªt pour preprocessing_timeseries.py")
        
        # Afficher un aperÃ§u
        print(f"\nğŸ‘€ AperÃ§u du dataset:")
        # Utiliser les vraies colonnes du CSV
        available_cols = ['participants_ID', 'indication', 'age', 'gender', 'split']
        # VÃ©rifier quelles colonnes existent rÃ©ellement
        existing_cols = [col for col in available_cols if col in dataset.columns]
        if len(existing_cols) > 0:
            print(dataset[existing_cols].head(10))
        else:
            print("Colonnes disponibles:", list(dataset.columns)[:10])
        
    else:
        print(f"\nğŸ’¥ Ã‰chec de la crÃ©ation du dataset")

if __name__ == "__main__":
    main()